# 01_web_crawling.ipynb

"""
ğŸ‡»ğŸ‡³ **Má»¥c tiÃªu:** Thu tháº­p dá»¯ liá»‡u máº¡ng xÃ£ há»™i tá»« cÃ¡c fanpage chÃ­nh thá»©c cá»§a Coke, Pepsi vÃ  Fanta trÃªn Facebook, Instagram vÃ  YouTube trong khoáº£ng thá»i gian tá»« 01/11/2024 Ä‘áº¿n 31/03/2025.

ğŸ‡¬ğŸ‡§ **Objective:** Collect social media data from the official pages of Coke, Pepsi, and Fanta on Facebook, Instagram, and YouTube from November 1, 2024 to March 31, 2025.
"""

import os
import pandas as pd
from datetime import datetime
from facebook_scraper import get_posts

# -----------------------------
# 1. CRAWL FACEBOOK POSTS
# -----------------------------

# ğŸ‡»ğŸ‡³ Táº¡o hÃ m thu tháº­p bÃ i Ä‘Äƒng tá»« Facebook
# ğŸ‡¬ğŸ‡§ Create function to scrape Facebook posts
def crawl_facebook_page(page_name, start_date, end_date, max_posts=500):
    posts_data = []
    for post in get_posts(page_name, pages=50, options={"comments": False}):
        if 'time' not in post:
            continue
        post_time = post['time']
        if post_time < start_date:
            break
        if start_date <= post_time <= end_date:
            posts_data.append({
                'platform': 'Facebook',
                'brand': page_name,
                'time': post_time,
                'text': post.get('text', ''),
                'likes': post.get('likes', 0),
                'shares': post.get('shares', 0),
                'comments': post.get('comments', 0),
                'post_url': post.get('post_url', '')
            })
    return posts_data

# ğŸ‡»ğŸ‡³ Khai bÃ¡o fanpage cáº§n thu tháº­p
# ğŸ‡¬ğŸ‡§ Define Facebook fanpages
facebook_pages = {
    'Coke': 'TCCCVN',
    'Pepsi': 'Pepsivietnam',
    'Fanta': 'fantavietnam'
}

start = datetime(2024, 11, 1)
end = datetime(2025, 3, 31)

facebook_data = []
for brand, page in facebook_pages.items():
    facebook_data.extend(crawl_facebook_page(page, start, end))

# -----------------------------
# 2. MOCK INSTAGRAM DATA
# -----------------------------

# ğŸ‡»ğŸ‡³ MÃ´ phá»ng dá»¯ liá»‡u Instagram vÃ¬ API giá»›i háº¡n quyá»n truy cáº­p
# ğŸ‡¬ğŸ‡§ Mock Instagram data due to API limitations
instagram_data = []
for brand in ['Coke', 'Pepsi', 'Fanta']:
    for i in range(20):
        instagram_data.append({
            'platform': 'Instagram',
            'brand': brand,
            'time': datetime(2025, 1, i+1),
            'text': f"Sample Instagram post {i+1} from {brand}",
            'likes': 100 + i,
            'shares': 0,
            'comments': 10 + i,
            'post_url': f"https://instagram.com/{brand.lower()}/post/{i+1}"
        })

# -----------------------------
# 3. MOCK YOUTUBE DATA
# -----------------------------

# ğŸ‡»ğŸ‡³ MÃ´ phá»ng dá»¯ liá»‡u YouTube
# ğŸ‡¬ğŸ‡§ Mock YouTube data
youtube_data = []
for brand in ['Coke', 'Pepsi', 'Fanta']:
    for i in range(10):
        youtube_data.append({
            'platform': 'YouTube',
            'brand': brand,
            'time': datetime(2025, 2, i+1),
            'text': f"Sample YouTube video {i+1} from {brand}",
            'likes': 300 + i,
            'shares': 50,
            'comments': 20 + i,
            'post_url': f"https://youtube.com/{brand.lower()}/video/{i+1}"
        })

# -----------------------------
# 4. SAVE DATA TO CSV
# -----------------------------

# ğŸ‡»ğŸ‡³ LÆ°u toÃ n bá»™ dá»¯ liá»‡u vÃ o file
# ğŸ‡¬ğŸ‡§ Save all data to file
all_data = facebook_data + instagram_data + youtube_data

df = pd.DataFrame(all_data)
os.makedirs("data", exist_ok=True)
df.to_csv("data/social_media_data.csv", index=False)

print("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o data/social_media_data.csv")
