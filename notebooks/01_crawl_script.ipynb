# 01_web_crawling.ipynb

# Author: Hoang Ngoc Anh
# Description: Crawling social media data for Coke, Pepsi, and Fanta
# Platforms: Facebook (real crawling), Instagram & YouTube (simulated)

import os
import pandas as pd
from datetime import datetime, timedelta
from facebook_scraper import get_posts

# Define brands and their Facebook page names
brands = {
    "CocaCola": "TCCCVN",
    "Pepsi": "Pepsivietnam",
    "Fanta": "fantavietnam"
}

# Define crawling period (minimum 2 months)
end_date = datetime.today()
start_date = end_date - timedelta(days=60)

# Function to crawl Facebook posts

def crawl_facebook(page_name, brand, start_date, end_date):
    all_posts = []
    for post in get_posts(page_name, pages=50, extra_info=True):
        post_date = post["time"]
        if post_date is None:
            continue
        if start_date <= post_date <= end_date:
            post_data = {
                "brand": brand,
                "platform": "Facebook",
                "post_id": post.get("post_id"),
                "text": post.get("text"),
                "time": post_date,
                "likes": post.get("likes"),
                "comments": post.get("comments"),
                "shares": post.get("shares"),
                "post_url": post.get("post_url"),
            }
            all_posts.append(post_data)
        elif post_date < start_date:
            break
    return all_posts

# Crawl data for all brands on Facebook
all_facebook_data = []
for brand, page in brands.items():
    print(f"Crawling Facebook data for {brand}...")
    brand_posts = crawl_facebook(page, brand, start_date, end_date)
    all_facebook_data.extend(brand_posts)

facebook_df = pd.DataFrame(all_facebook_data)
facebook_df.to_csv("../data/facebook_data.csv", index=False)
print("Facebook data saved.")

# Simulate Instagram and YouTube data (mock-up)
def simulate_instagram_data():
    data = []
    for brand in brands:
        for i in range(20):
            data.append({
                "brand": brand,
                "platform": "Instagram",
                "post_id": f"{brand}_IG_{i}",
                "text": f"This is a sample Instagram post {i} by {brand}",
                "time": (start_date + timedelta(days=i)).strftime('%Y-%m-%d'),
                "likes": 100 + i * 3,
                "comments": 20 + i,
                "shares": 0,
                "post_url": f"https://instagram.com/{brand}/post/{i}"
            })
    return pd.DataFrame(data)

def simulate_youtube_data():
    data = []
    for brand in brands:
        for i in range(10):
            data.append({
                "brand": brand,
                "platform": "YouTube",
                "post_id": f"{brand}_YT_{i}",
                "text": f"This is a simulated YouTube video description {i} by {brand}",
                "time": (start_date + timedelta(days=i*3)).strftime('%Y-%m-%d'),
                "likes": 200 + i * 5,
                "comments": 40 + i,
                "shares": 15 + i,
                "post_url": f"https://youtube.com/watch?v=simulated_{i}"
            })
    return pd.DataFrame(data)

insta_df = simulate_instagram_data()
yt_df = simulate_youtube_data()

insta_df.to_csv("../data/instagram_data.csv", index=False)
yt_df.to_csv("../data/youtube_data.csv", index=False)
print("Simulated Instagram and YouTube data saved.")

# Combine all into one dataset
combined_df = pd.concat([facebook_df, insta_df, yt_df])
combined_df.to_csv("../data/combined_social_data.csv", index=False)
print("All platform data combined and saved.")
