import pandas as pd
from facebook_scraper import get_posts, set_cookies
from textblob import TextBlob
from datetime import datetime, timedelta
import os, random
from IPython.display import display  # ‚úÖ Cho b·∫£ng ƒë·∫πp

# --- Configuration ---
BRAND = "Pepsi"
PAGE_NAME = "Pepsivietnam"
START_DATE = datetime(2024, 11, 1)
END_DATE = datetime(2025, 3, 31)
OUTPUT_PATH = "data/crawl_pepsi_data.csv"
os.makedirs("data", exist_ok=True)

# --- Sentiment analysis ---
def get_sentiment(text):
    if not text:
        return "Neutral"
    score = TextBlob(text).sentiment.polarity
    if score > 0.1:
        return "Positive"
    elif score < -0.1:
        return "Negative"
    else:
        return "Neutral"

# --- Post type guess ---
def guess_post_type(text, platform):
    if platform == "YouTube": return "video"
    if platform == "Instagram": return random.choice(["reel", "image", "video"])
    if platform == "Facebook":
        if "video" in text.lower(): return "video"
        elif len(text.split()) > 50: return "text"
        else: return "image"
    return "text"

# --- Facebook real crawling (with cookies) ---
def crawl_facebook_pepsi():
    print("üîç Crawling Facebook...")
    set_cookies("cookies.json")  # Upload file cookies.json
    posts = []
    for post in get_posts(PAGE_NAME, pages=20, extra_info=True):
        date = post.get("time")
        if not date or date < START_DATE: break
        if date > END_DATE: continue
        text = post.get("text", "").strip()
        posts.append({
            "brand": BRAND,
            "platform": "Facebook",
            "post_id": post.get("post_id"),
            "time": date.strftime("%Y-%m-%d %H:%M:%S"),
            "content": text,
            "likes": post.get("likes", 0),
            "comments": post.get("comments", 0),
            "shares": post.get("shares", 0),
            "reactions": sum([post.get("likes", 0), post.get("comments", 0), post.get("shares", 0)]),
            "post_type": guess_post_type(text, "Facebook"),
            "sentiment": get_sentiment(text),
            "post_url": post.get("post_url", "")
        })
    return pd.DataFrame(posts)

# --- Instagram mock ---
def simulate_instagram_pepsi():
    print("üé® Simulating Instagram...")
    data = []
    for i in range(20):
        t = START_DATE + timedelta(days=i * 5)
        text = f"Pepsi IG mock post #{i} ‚Äì #PepsiVibes"
        likes = random.randint(300, 1200)
        comments = random.randint(20, 80)
        data.append({
            "brand": BRAND,
            "platform": "Instagram",
            "post_id": f"pepsi_ig_{i}",
            "time": t.strftime("%Y-%m-%d %H:%M:%S"),
            "content": text,
            "likes": likes,
            "comments": comments,
            "shares": 0,
            "reactions": likes + comments,
            "post_type": guess_post_type(text, "Instagram"),
            "sentiment": get_sentiment(text),
            "post_url": f"https://www.instagram.com/pepsivietnam/posts/{i}"
        })
    return pd.DataFrame(data)

# --- YouTube mock ---
def simulate_youtube_pepsi():
    print("üé¨ Simulating YouTube...")
    data = []
    for i in range(10):
        t = START_DATE + timedelta(days=i * 10)
        text = f"Watch Pepsi YouTube Campaign #{i}"
        likes = random.randint(1000, 3000)
        comments = random.randint(40, 150)
        shares = random.randint(10, 50)
        data.append({
            "brand": BRAND,
            "platform": "YouTube",
            "post_id": f"pepsi_yt_{i}",
            "time": t.strftime("%Y-%m-%d %H:%M:%S"),
            "content": text,
            "likes": likes,
            "comments": comments,
            "shares": shares,
            "reactions": likes + comments + shares,
            "post_type": guess_post_type(text, "YouTube"),
            "sentiment": get_sentiment(text),
            "post_url": f"https://www.youtube.com/watch?v=pepsi_mock_{i}"
        })
    return pd.DataFrame(data)

# --- Merge & Export ---
def export_all():
    fb_df = crawl_facebook_pepsi()
    ig_df = simulate_instagram_pepsi()
    yt_df = simulate_youtube_pepsi()
    df = pd.concat([fb_df, ig_df, yt_df], ignore_index=True)
    df['time'] = pd.to_datetime(df['time'])
    df = df.sort_values(by='time')
    df.to_csv(OUTPUT_PATH, index=False, encoding='utf-8-sig')
    print(f"‚úÖ File saved to {OUTPUT_PATH} ({len(df)} rows)")
    return df

# --- Run & display ---
if __name__ == "__main__":
    df = export_all()

    # ‚úÖ Hi·ªÉn th·ªã b·∫£ng r√µ r√†ng
    styled_df = (
        df[['time', 'platform', 'content', 'likes', 'comments', 'shares', 'reactions', 'sentiment']]
        .sort_values(by='time', ascending=False)
        .head(30)
        .style.set_caption("üìã Top Pepsi Posts (Nov 2024 ‚Äì Mar 2025)")
        .format({
            "likes": "{:,.0f}",
            "comments": "{:,.0f}",
            "shares": "{:,.0f}",
            "reactions": "{:,.0f}"
        })
        .set_properties(**{
            'background-color': '#f9f9f9',
            'border': '1px solid #ccc',
            'text-align': 'left',
            'padding': '8px'
        })
        .set_table_styles([
            {'selector': 'th', 'props': [('text-align', 'center'), ('background-color', '#ececec')]}
        ])
    )

    display(styled_df)
